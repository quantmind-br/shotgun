# Test Design: Story 3.4

**Date**: 2025-09-04  
**Designer**: Quinn (Test Architect)  
**Story**: 3.4 - Prompt Generation & File Writing

## Test Strategy Overview

- **Total test scenarios**: 22
- **Unit tests**: 12 (55%)
- **Integration tests**: 7 (32%)  
- **E2E tests**: 3 (13%)
- **Priority distribution**: P0: 8, P1: 10, P2: 4

## Test Scenarios by Acceptance Criteria

### AC1: Combine template + variables + file structure into final output

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-001 | Unit        | P0       | Template processing with variables      | Core business logic isolation    |
| 3.4-UNIT-002 | Unit        | P0       | File structure assembly algorithm       | Complex assembly logic           |
| 3.4-UNIT-003 | Unit        | P1       | Variable substitution edge cases        | Data transformation validation   |
| 3.4-INT-001  | Integration | P0       | Template engine integration             | Critical component interaction   |
| 3.4-INT-002  | Integration | P1       | File structure builder integration      | Multi-component data flow        |

### AC2: Save to current directory with timestamp filename

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-004 | Unit        | P0       | Timestamp filename generation           | Pure function, algorithm logic   |
| 3.4-UNIT-005 | Unit        | P1       | Filename validation and sanitization    | Input validation logic           |
| 3.4-INT-003  | Integration | P0       | File write operations                   | File system interaction          |
| 3.4-E2E-001  | E2E         | P1       | End-to-end file generation              | Critical user journey            |

### AC3: Ensure no filename collisions with incrementing counter

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-006 | Unit        | P0       | Collision detection algorithm           | Complex logic with edge cases    |
| 3.4-UNIT-007 | Unit        | P1       | Counter increment logic                 | Algorithm correctness            |
| 3.4-INT-004  | Integration | P1       | Concurrent collision handling           | File system race conditions      |

### AC4: Display success message with full file path

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-008 | Unit        | P2       | Success message formatting              | Display logic validation         |
| 3.4-INT-005  | Integration | P1       | UI state update after generation        | Component interaction            |
| 3.4-E2E-002  | E2E         | P1       | Complete success flow display           | User experience validation       |

### AC5: Handle write errors gracefully with clear error message

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-009 | Unit        | P0       | Error message generation                | Critical error handling logic    |
| 3.4-UNIT-010 | Unit        | P1       | Error categorization logic              | Error classification algorithm   |
| 3.4-INT-006  | Integration | P0       | Write failure error propagation         | Cross-component error handling   |
| 3.4-E2E-003  | E2E         | P2       | User error recovery flow                | Error scenario user experience   |

### AC6: Non-blocking generation using goroutines

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-011 | Unit        | P1       | Goroutine cleanup on cancellation       | Concurrency logic validation     |
| 3.4-INT-007  | Integration | P0       | Async generation command flow           | Bubble Tea integration           |

### AC7: Progress indicator during file writing for large outputs

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                    |
| ------------ | ----------- | -------- | --------------------------------------- | -------------------------------- |
| 3.4-UNIT-012 | Unit        | P2       | Progress calculation algorithm          | Mathematical correctness         |

## Risk Coverage

**Mapping to identified risks from risk profile:**

- **TECH-001 (File I/O failures)**: Covered by 3.4-INT-003, 3.4-INT-006, 3.4-E2E-003
- **PERF-001 (Memory exhaustion)**: Addressed through large output test scenarios
- **TECH-002 (Concurrency issues)**: Covered by 3.4-UNIT-011, 3.4-INT-007, 3.4-INT-004
- **DATA-001 (Template injection)**: Covered by 3.4-UNIT-001, 3.4-UNIT-003
- **OPS-001 (Error context)**: Covered by 3.4-UNIT-009, 3.4-UNIT-010, 3.4-INT-006

## Detailed Test Specifications

### P0 Critical Tests (Must Execute)

#### 3.4-UNIT-001: Template Processing with Variables
```gherkin
Given a template with TASK, RULES, and FILE_STRUCTURE variables
When the template is processed with provided values
Then the output contains all substituted variables
And automatic variables (CURRENT_DATE, PROJECT_NAME) are populated
And conditional sections are processed correctly
```

#### 3.4-UNIT-002: File Structure Assembly Algorithm  
```gherkin
Given selected files with various formats and sizes
When the file structure is assembled
Then files are wrapped in proper XML tags
And tree structure is maintained with ASCII characters
And binary files are skipped with appropriate messages
```

#### 3.4-UNIT-004: Timestamp Filename Generation
```gherkin
Given current timestamp and base filename pattern
When filename is generated
Then format follows shotgun_prompt_YYYYMMDD_HHMM.md pattern
And timestamp is accurate to current time
And filename is valid across platforms (Windows/Unix)
```

#### 3.4-UNIT-006: Collision Detection Algorithm
```gherkin
Given an existing file with timestamp filename
When a new file with same timestamp is generated
Then collision is detected correctly
And counter suffix is appended (_1, _2, etc.)
And process continues until unique filename found
```

#### 3.4-UNIT-009: Error Message Generation
```gherkin
Given various error conditions (permissions, disk space, locked files)
When error occurs during file operations
Then error message includes specific failure reason
And message provides actionable guidance
And error context includes file paths and operation details
```

#### 3.4-INT-001: Template Engine Integration
```gherkin
Given GenerationConfig with template and variables
When PromptGenerator processes the configuration
Then existing template engine is called correctly
And all variables are passed through properly
And template processing errors are handled gracefully
```

#### 3.4-INT-003: File Write Operations
```gherkin
Given generated prompt content and target filename
When WritePromptFile is executed
Then atomic file operations are used (temp â†’ rename)
And file permissions are validated before write
And write errors are captured and categorized
```

#### 3.4-INT-007: Async Generation Command Flow
```gherkin
Given generation request from confirmation screen
When async generation command is executed
Then Bubble Tea command pattern is followed correctly
And UI remains responsive during generation
And progress updates are sent to UI properly
```

### P1 High Priority Tests (Should Execute)

#### 3.4-UNIT-003: Variable Substitution Edge Cases
```gherkin
Given template variables with special characters, empty values, and large content
When template processing occurs
Then special characters are properly escaped
And empty variables are handled gracefully
And large variable content doesn't cause memory issues
```

#### 3.4-UNIT-005: Filename Validation and Sanitization
```gherkin
Given various filename scenarios (invalid characters, reserved names, long paths)
When filename generation occurs
Then invalid characters are removed or replaced
And Windows reserved names are avoided
And path length limits are respected
```

#### 3.4-UNIT-007: Counter Increment Logic
```gherkin
Given existing files with counter suffixes (_1, _2, _3)
When collision detection runs
Then next available counter is calculated correctly
And logic handles gaps in numbering sequence
And maximum reasonable counter limits are enforced
```

#### 3.4-UNIT-010: Error Categorization Logic
```gherkin
Given different types of file operation errors
When error occurs
Then error is categorized correctly (permission, space, lock, etc.)
And appropriate recovery suggestions are provided
And error severity levels are assigned properly
```

#### 3.4-UNIT-011: Goroutine Cleanup on Cancellation
```gherkin
Given generation in progress with active goroutines
When user cancels operation
Then all goroutines are properly terminated
And context cancellation propagates correctly
And no resource leaks occur
```

#### 3.4-INT-002: File Structure Builder Integration
```gherkin
Given selected files from AppState
When file structure assembly occurs
Then existing FileStructureBuilder is used correctly
And file order matches confirmation screen display
And XML format consistency is maintained
```

#### 3.4-INT-004: Concurrent Collision Handling
```gherkin
Given multiple processes attempting to write same filename
When collision detection runs concurrently
Then race conditions are avoided
And each process gets unique filename
And file locking prevents corruption
```

#### 3.4-INT-005: UI State Update After Generation
```gherkin
Given completed generation with success/error result
When UI state update occurs
Then AppState is updated with generation results
And success/error screen is displayed appropriately
And user can navigate to next actions
```

#### 3.4-E2E-001: End-to-End File Generation
```gherkin
Given user has completed confirmation screen
When F10 is pressed to start generation
Then prompt is generated successfully
And file is written to filesystem
And success message displays full path and statistics
```

#### 3.4-E2E-002: Complete Success Flow Display
```gherkin
Given successful prompt generation
When success screen is displayed
Then file path, size, and statistics are shown
And user can navigate with F1, F2, Esc keys
And F2 opens file in system default application
```

### P2 Medium Priority Tests (Nice to Execute)

#### 3.4-UNIT-008: Success Message Formatting
```gherkin
Given successful generation with file details
When success message is formatted
Then message includes file name, path, and size
And formatting is consistent with UI design
And message handles long file paths gracefully
```

#### 3.4-UNIT-012: Progress Calculation Algorithm
```gherkin
Given generation stages and current progress
When progress percentage is calculated
Then calculation is accurate for each stage
And progress never decreases or exceeds 100%
And progress updates are smooth and meaningful
```

#### 3.4-E2E-003: User Error Recovery Flow
```gherkin
Given file write error during generation
When error screen is displayed
Then clear error message and suggestions are shown
And user can retry with F5 or restart with F1
And error context helps user resolve issue
```

## Performance and Load Test Scenarios

### Large Output Handling
- **Test**: Generate prompts with 1000+ files, 100MB+ total size
- **Validate**: Memory usage stays reasonable, streaming writes work
- **Monitor**: Generation time, UI responsiveness

### Memory Management
- **Test**: Monitor memory usage during large file processing
- **Validate**: No memory leaks, gradual memory release
- **Threshold**: Memory usage <1GB for reasonable file sets

### Concurrent Operations
- **Test**: Multiple generation attempts, cancellation scenarios
- **Validate**: Proper resource cleanup, no race conditions
- **Monitor**: Goroutine count, context cancellation timing

## Test Environment Requirements

### Unit Tests
- **Environment**: Standard Go test environment
- **Mocks**: Template engine, file system operations
- **Fixtures**: Sample templates, mock file structures

### Integration Tests  
- **Environment**: Test filesystem, temp directories
- **Dependencies**: Real template engine, controlled file system
- **Cleanup**: Automated test file cleanup

### E2E Tests
- **Environment**: Full application with test data
- **Dependencies**: Complete AppState setup, real file system
- **Validation**: Visual verification of UI states

## Test Data Requirements

### Templates
- Simple template with basic variables
- Complex template with conditionals and functions
- Template with special characters and edge cases

### File Sets
- Small file set (5-10 files, <1MB)
- Medium file set (50-100 files, 10-50MB)  
- Large file set (500+ files, 100MB+)
- Mixed binary and text files

### Error Scenarios
- Permission denied directories
- Disk full simulations
- File lock conflicts
- Invalid filename characters

## Recommended Execution Order

### Phase 1: P0 Unit Tests (Fast Feedback)
1. 3.4-UNIT-001 (Template processing)
2. 3.4-UNIT-002 (File structure assembly)
3. 3.4-UNIT-004 (Filename generation)
4. 3.4-UNIT-006 (Collision detection)
5. 3.4-UNIT-009 (Error message generation)

### Phase 2: P0 Integration Tests
1. 3.4-INT-001 (Template engine integration)
2. 3.4-INT-003 (File write operations)
3. 3.4-INT-006 (Error propagation)
4. 3.4-INT-007 (Async generation flow)

### Phase 3: P1 Tests (Core Functionality)
Execute all P1 unit and integration tests to validate core functionality.

### Phase 4: E2E and P2 Tests
Complete user journey validation and nice-to-have scenarios.

### Phase 5: Performance Tests
Execute large output and memory management tests.

## Test Automation Strategy

### Unit Tests
- Automated in CI/CD pipeline
- Run on every code commit
- Fast execution (<30 seconds total)
- Comprehensive mocking strategy

### Integration Tests
- Automated in CI/CD pipeline
- Require test environment setup
- Medium execution time (2-5 minutes)
- Use containerized dependencies where needed

### E2E Tests
- Automated for P1 scenarios
- P2 scenarios may be manual
- Slower execution (5-15 minutes)
- Full application environment required

## Test Coverage Validation

### Requirements Traceability
- âœ… Every AC has at least one test scenario
- âœ… All critical risks are covered by test scenarios
- âœ… No duplicate coverage across test levels

### Coverage Goals
- **Unit**: >90% code coverage for core generation logic
- **Integration**: >80% coverage of component interactions
- **E2E**: 100% coverage of critical user journeys

### Quality Gates
- P0 tests must pass for release
- P1 tests should pass (can be waived with risk assessment)
- P2 tests are nice-to-have for full regression cycles