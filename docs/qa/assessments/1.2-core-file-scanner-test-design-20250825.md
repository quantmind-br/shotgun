# Test Design: Story 1.2 - Core File Scanner Engine with Concurrency

Date: 2025-08-25
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 24
- Unit tests: 14 (58%)
- Integration tests: 7 (29%)
- E2E tests: 3 (13%)
- Priority distribution: P0: 10, P1: 8, P2: 4, P3: 2

## Test Scenarios by Acceptance Criteria

### AC1: FileScanner struct implemented with concurrent goroutine-based directory traversal

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-001 | Unit        | P0       | FileScanner struct initialization       | Core struct validation            |
| 1.2-UNIT-002 | Unit        | P0       | Directory traversal algorithm           | Pure traversal logic              |
| 1.2-UNIT-003 | Unit        | P1       | Concurrent goroutine spawn control      | Concurrency management logic      |
| 1.2-INT-001  | Integration | P0       | Full directory scan with goroutines     | Component interaction validation  |
| 1.2-E2E-001  | E2E         | P1       | Real project directory scanning         | End-to-end workflow verification  |

### AC2: Worker pool pattern using runtime.NumCPU() for optimal performance

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-004 | Unit        | P0       | Worker pool size calculation            | CPU-based sizing logic            |
| 1.2-UNIT-005 | Unit        | P0       | Worker pool creation and management     | Pool lifecycle management         |
| 1.2-UNIT-006 | Unit        | P1       | Worker task distribution algorithm      | Load balancing logic              |
| 1.2-INT-002  | Integration | P0       | Worker pool under concurrent load       | Pool behavior under stress        |
| 1.2-INT-003  | Integration | P1       | Worker pool resource cleanup            | Resource management validation    |

### AC3: Channel-based file information streaming to prevent memory bottlenecks

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-007 | Unit        | P0       | Channel creation and configuration      | Channel setup validation          |
| 1.2-UNIT-008 | Unit        | P0       | File information streaming logic        | Data flow algorithm               |
| 1.2-UNIT-009 | Unit        | P1       | Channel buffer size optimization        | Memory management logic           |
| 1.2-INT-004  | Integration | P0       | End-to-end streaming with large dataset | Memory bottleneck prevention      |
| 1.2-INT-005  | Integration | P1       | Channel closure and cleanup             | Resource lifecycle management     |

### AC4: Basic binary file detection using h2non/filetype library

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-010 | Unit        | P1       | Binary file detection accuracy          | Detection algorithm validation    |
| 1.2-UNIT-011 | Unit        | P1       | File type classification logic          | Classification algorithm          |
| 1.2-INT-006  | Integration | P1       | Binary detection in file scanning       | Integration with scanning process |
| 1.2-E2E-002  | E2E         | P2       | Binary file handling in full workflow   | User experience validation        |

### AC5: File metadata collection (size, modification time, type) for all discovered files

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-012 | Unit        | P1       | Metadata extraction accuracy            | Data extraction logic             |
| 1.2-UNIT-013 | Unit        | P1       | Metadata structure validation           | Data model validation             |
| 1.2-INT-007  | Integration | P1       | Metadata collection during scanning     | Integration with file processing  |

### AC6: Performance requirement - scan 1000+ files in under 5 seconds

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-014 | Unit        | P0       | Performance benchmark baseline          | Isolated performance validation   |
| 1.2-E2E-003  | E2E         | P0       | Large repository performance test       | Real-world performance validation |

### AC7: Graceful error handling for permission denied and other file system errors

#### Scenarios

| ID           | Level       | Priority | Test                                    | Justification                      |
| ------------ | ----------- | -------- | --------------------------------------- | ---------------------------------- |
| 1.2-UNIT-015 | Unit        | P0       | Permission denied error handling        | Error handling logic              |
| 1.2-UNIT-016 | Unit        | P0       | File system error classification        | Error categorization logic        |
| 1.2-UNIT-017 | Unit        | P1       | Error recovery mechanisms               | Recovery logic validation         |
| 1.2-INT-008  | Integration | P0       | Error handling in concurrent context    | Concurrent error management       |
| 1.2-E2E-004  | E2E         | P1       | User experience during error scenarios  | Error UX validation               |

## Risk Coverage Analysis

Based on the risk profile assessment, these test scenarios address:

**Critical Risks Mitigated:**
- **PERF-001** (Memory exhaustion): AC3 scenarios validate streaming approach
- **OPS-001** (Silent failures): AC7 scenarios ensure proper error handling

**High Risks Mitigated:**
- **TECH-001** (Cross-platform): E2E tests should run on multiple platforms
- **PERF-002** (UI responsiveness): Performance tests validate background processing

**Medium Risks Mitigated:**
- **PERF-003** (File scanning timeouts): Performance benchmarks catch timeout risks
- **OPS-002** (Build complexity): Integration tests validate component assembly

## Detailed Test Scenarios

### Unit Tests (P0 Priority)

**1.2-UNIT-001: FileScanner Initialization**
```go
func TestFileScanner_Initialization(t *testing.T) {
    scanner := NewFileScanner()
    assert.NotNil(t, scanner)
    assert.Equal(t, runtime.NumCPU(), scanner.WorkerCount())
    assert.NotNil(t, scanner.resultChannel)
}
```

**1.2-UNIT-002: Directory Traversal Algorithm**
```go
func TestFileScanner_DirectoryTraversal(t *testing.T) {
    // Test with known directory structure
    // Verify all files and subdirectories found
    // Validate traversal order and completeness
}
```

**1.2-UNIT-004: Worker Pool Size Calculation**
```go
func TestWorkerPool_OptimalSizing(t *testing.T) {
    pool := NewWorkerPool()
    expectedSize := runtime.NumCPU()
    assert.Equal(t, expectedSize, pool.Size())
    
    // Test with custom sizing
    customPool := NewWorkerPoolWithSize(8)
    assert.Equal(t, 8, customPool.Size())
}
```

### Integration Tests (P0 Priority)

**1.2-INT-001: Full Directory Scan with Goroutines**
```go
func TestFileScanner_ConcurrentScan(t *testing.T) {
    // Create test directory with 100+ files
    // Scan with goroutines
    // Verify all files found
    // Validate concurrent execution (timing-based)
}
```

**1.2-INT-002: Worker Pool Under Load**
```go
func TestWorkerPool_ConcurrentLoad(t *testing.T) {
    // Submit 1000+ tasks to worker pool
    // Verify all tasks completed
    // Check resource usage stays bounded
    // Validate no goroutine leaks
}
```

### E2E Tests (P0 Priority)

**1.2-E2E-003: Large Repository Performance**
```go
func TestFileScanner_LargeRepoPerformance(t *testing.T) {
    // Create test repo with 1000+ files
    // Measure scan time
    // Assert completion under 5 seconds
    // Validate memory usage stays under limits
}
```

## Test Data Requirements

### Unit Test Data
- Mock file system structures (in-memory)
- Predefined file metadata sets
- Error condition simulations
- Performance timing baselines

### Integration Test Data
- Small test directories (10-50 files)
- Medium test repositories (100-500 files)
- Mixed file types (text, binary, special)
- Permission-restricted directories

### E2E Test Data
- Large test repository (1000+ files)
- Real-world project structures
- Cross-platform file system variations
- Network-mounted directories (for error testing)

## Recommended Execution Order

### Phase 1: Core Validation (P0 Units)
1. 1.2-UNIT-001: FileScanner initialization
2. 1.2-UNIT-002: Directory traversal algorithm
3. 1.2-UNIT-004: Worker pool sizing
4. 1.2-UNIT-005: Worker pool management
5. 1.2-UNIT-007: Channel creation
6. 1.2-UNIT-008: File streaming logic
7. 1.2-UNIT-015: Permission error handling
8. 1.2-UNIT-016: Error classification

### Phase 2: Component Integration (P0 Integration)
9. 1.2-INT-001: Concurrent directory scan
10. 1.2-INT-002: Worker pool under load
11. 1.2-INT-004: Memory-safe streaming
12. 1.2-INT-008: Concurrent error handling

### Phase 3: Performance Validation (P0 E2E)
13. 1.2-UNIT-014: Performance baseline
14. 1.2-E2E-003: Large repository test

### Phase 4: Extended Coverage (P1/P2)
15. All remaining P1 scenarios
16. P2 scenarios as time permits

## Test Environment Requirements

### Hardware Specifications
- Multi-core CPU (4+ cores) for concurrency testing
- Minimum 8GB RAM for large dataset tests
- SSD storage for performance consistency
- Network access for error simulation

### Software Requirements
- Go 1.22+ test environment
- File system utilities for test data creation
- Memory profiling tools (pprof)
- Cross-platform test runners (Windows/Linux/macOS)

### Test Data Management
- Automated test data generation scripts
- Cleanup procedures for temporary directories
- Version control for golden datasets
- Performance baseline storage

## Maintenance Considerations

### Test Stability
- Use deterministic test data
- Avoid timing-dependent assertions where possible
- Implement retry mechanisms for flaky scenarios
- Mock external dependencies (file system, OS APIs)

### Performance Benchmarking
- Establish baseline measurements
- Track performance regression over time
- Use consistent hardware for benchmark runs
- Report performance trends in CI/CD

### Cross-Platform Compatibility
- Run core tests on all target platforms
- Platform-specific test variations where needed
- File system behavior differences handling
- Unicode/encoding test coverage

## Success Criteria

### Test Coverage Goals
- 100% coverage of acceptance criteria
- 90%+ line coverage for FileScanner package
- All P0 tests passing before merge
- Performance benchmarks within acceptable limits

### Quality Gates
- No P0 test failures allowed
- Performance regression < 10% from baseline
- Memory leaks detection and prevention
- Error handling completeness validation

This comprehensive test design ensures the Core File Scanner Engine meets all requirements while maintaining high performance and reliability standards. The test strategy balances thorough validation with efficient execution, prioritizing critical paths while ensuring comprehensive coverage of the concurrent file processing system.